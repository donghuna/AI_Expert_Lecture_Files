{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463a2f4b",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/dshan4585/AI_Expert_Lecture_Files/blob/main/Lab4_using_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "197f9b5e-5225-4366-9c4d-df74c6a459ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b0c42",
   "metadata": {},
   "source": [
    "#### Load Microsoft Phi3 model (Phi-3-mini-128k-instruct) and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "097f2358-8bdd-4c38-b687-885ce5b6b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cabec8d-fc0b-4e23-8add-fd2cddb6a4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attenton` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ccb77771f0142be9390ac6df1562cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17d07ead0384fb2960ed9f712af8fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07e1b6d45a64df8bfa85aa1238807d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876828128f7748fd9b8339ea5713e834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41415e35e2e7425387c5ef44bd946d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01185b9721504f76a7f484e6a7f47959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/172 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.random.manual_seed(0)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-128k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd6721e-1c2d-4cad-8392-9ba9504887ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411927c104984286a2ca34e34af67b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23e54c8f50445eaac5732c21d970849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f257c7cd17d746f585c7ccd41a8994e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654ecad0d20648288bf53a13572186e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc75ca5536a34bd8a1c08b6e954e3a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/568 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ace16ee-2ee1-4365-b0fb-e88badda68e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Sure! Here are some ways to eat bananas and dragonfruits together: 1. Banana and dragonfruit smoothie: Blend bananas and dragonfruits together with some milk and honey. 2. Banana and dragonfruit salad: Mix sliced bananas and dragonfruits together with some lemon juice and honey.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What about solving an 2x + 3 = 7 equation?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea91548b-c876-41a6-af7c-1120051ff04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d445bfb9-dfcc-4238-83b2-cf48888ada93",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0.0,\n",
    "    \"do_sample\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a24bfcf-510e-41c7-a37c-90c5be3bc8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To solve the equation 2x + 3 = 7, you need to isolate the variable x. Here are the steps:\n",
      "\n",
      "1. Subtract 3 from both sides of the equation to get rid of the +3 on the left side. This gives you: 2x = 7 - 3, which simplifies to 2x = 4.\n",
      "\n",
      "2. Now, divide both sides of the equation by 2 to solve for x. This gives you: x = 4 / 2, which simplifies to x = 2.\n",
      "\n",
      "So, the solution to the equation 2x + 3 = 7 is x = 2.\n"
     ]
    }
   ],
   "source": [
    "output = pipe(messages, **generation_args)\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ca753b3-1f07-40a9-a668-ff9c50e8a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages2 = [\n",
    "    {\"role\": \"user\", \"content\": \"Please Name three of name red flowers\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f50d4b5f-1896-409e-8fe1-4c606ad9ca8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. Red Rose\n",
      "\n",
      "2. Poinsettia\n",
      "\n",
      "3. Firecracker Flower (Tricyrtis hirta)\n"
     ]
    }
   ],
   "source": [
    "output = pipe(messages2, **generation_args)\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a6776b6-a02b-49b0-a261-03c313713a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1l\u001b>1753 \u001b[30m\u001b[1mgdm       \u001b[15;27H\u001b[m\u001b[32m3\u001b[36m758M  166M  102\u001b[15;55H\u001b[m\u001b[m1  3:56.26\u001b[10Cgnome-\u001b[16;63H40\u001b[H14;4H1322 \u001b[30m\u001b[1mroot      \u001b[m\u001b[m 20   0 \u001b[36m 256M 15\u001b[m\u001b[m872 \u001b[36m14\u001b[m\u001b[m336 S  0.7  0.0 \u001b[31m\u001b[1m 1h\u001b[m\u001b[m07:16 /usr/sbin/Netwo\u001b[15;7H0\u001b[15;48H0.7\u001b[7C1:08.70 /usr/bin/python\u001b[16;4H1614\u001b[16;27H\u001b[32m27\u001b[36m.4\u001b[32mG 1\u001b[36m254M  394M \u001b[m\u001b[mS \u001b[16;55H5\u001b[7C39 \u001b[32m/usr/bin/python\u001b[1;1H\u001b[m\u001b[m\u001b[8;65H\u001b[36m\u001b[1m8\u001b[11;48H\u001b[m\u001b[30m\u001b[46m5.7\u001b[12;63H\u001b[m\u001b[m93\u001b[13;4H1610\u001b[13;27H\u001b[32m27\u001b[36m.4\u001b[32mG 1\u001b[36m254M  394M \u001b[m\u001b[mS  2.0  0.5  1:08.73 /usr/bin/python\u001b[14;2H262489 user      \u001b[14;27H\u001b[36m13\u001b[m\u001b[m268 \u001b[36m 4\u001b[m\u001b[m608 \u001b[36m 3\u001b[m\u001b[m072 \u001b[32mR \u001b[m\u001b[m 2.0\u001b[6C 0:00.21 htop\u001b[K\u001b[14;23r\u001b[14;1H\u001b[2M\u001b[1;24r\u001b[8;65H\u001b[36m\u001b[1m9\u001b[11;47H\u001b[m\u001b[30m\u001b[46m37.3\u001b[11;64H9\u001b[12;3H\u001b[m\u001b[m62489\u001b[12;27H\u001b[36m13\u001b[m\u001b[m268 \u001b[36m 4\u001b[m\u001b[m608 \u001b[36m 3\u001b[m\u001b[m072 \u001b[32mR \u001b[m\u001b[m 2.0  0.0  0:00.24 htop\u001b[K\u001b[13;48H1.3\u001b[13;64H5\u001b[11\u001b[22;4H1310 \u001b[30m\u001b[1mroot      \u001b[m\u001b[m 20   0 \u001b[36m 239M 10\u001b[m\u001b[m240 \u001b[36m 6\u001b[m\u001b[m656 S  0.0  0.0  0:39.62 /usr/libexec/ac\u001b[23;4H1311 \u001b[30m\u001b[1mroot      \u001b[m\u001b[m 20   0 \u001b[36m 2\u001b[m\u001b[m816 \u001b[36m 1\u001b[m\u001b[m536 \u001b[36m 1\u001b[m\u001b[m536 S  0.0  0.0  0:00.00 /usr/sbin/acpid\u001b[1;1H\u001b[?1000l\u001b[24;1H\u001b[2J\u001b[?47l\u001b8"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
