{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donghuna/AI_Expert_Lecture_Files/blob/main/Lab2_2_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-sbkFbNUAKyK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Compose,ToTensor\n",
        "\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-mCz91mryvd"
      },
      "source": [
        "#### Connect to local google drive & settings for export/import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_1Cr9tsrydl"
      },
      "outputs": [],
      "source": [
        "# drive.mount('/content/gdrive')\n",
        "# !mkdir ./gdrive/'My Drive'/MNIST_models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2nLnUERGaL_"
      },
      "source": [
        "#### DNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nV9KcFU1FKsR"
      },
      "outputs": [],
      "source": [
        "class MNISTDNN(nn.Module):\n",
        "    def __init__(self,IMG_SIZE=28):\n",
        "        super(MNISTDNN,self).__init__()\n",
        "        self.fc1 = nn.Linear(IMG_SIZE*IMG_SIZE,32)\n",
        "        self.BN1 = torch.nn.BatchNorm1d(32)\n",
        "        self.fc2 = nn.Linear(32,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.BN1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = torch.softmax(x,dim=-1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNCKxXJwGdN4"
      },
      "source": [
        "#### CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CvofB0pnGfHM"
      },
      "outputs": [],
      "source": [
        "class MNISTCNN(nn.Module):\n",
        "    def __init__(self,IMG_SIZE=28):\n",
        "        super(MNISTCNN,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,8,5,stride=2) # in_channels: int, out_channels: int, kernel_size: _size_2_t\n",
        "        self.BN1 = torch.nn.BatchNorm2d(8)\n",
        "        self.conv2 = nn.Conv2d(8,8,5,stride=2)\n",
        "        self.BN2 = torch.nn.BatchNorm2d(8)\n",
        "        self.conv3 = nn.Conv2d(8,8,3,stride=1)\n",
        "        self.fc = nn.Linear(8*2*2,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.BN1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.BN2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = x.view(-1,8*2*2)\n",
        "        x = self.fc(x)\n",
        "        x = torch.softmax(x,dim=-1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zyvh6IKYZcdi"
      },
      "source": [
        "#### Util function for calculating accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7YSzoolPQqIL"
      },
      "outputs": [],
      "source": [
        "def compute_acc(argmax,y):\n",
        "    count = 0\n",
        "    for i in range(len(argmax)):\n",
        "        if argmax[i]==y[i]:\n",
        "            count+=1\n",
        "    return count / len(argmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7KNrp6hGXWI"
      },
      "source": [
        "#### hyperparameters & datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vny-hSnYGOx5"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 28\n",
        "BATCH_SIZE = 256\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHES = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IpnCYlVHBuSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b07546-e88c-4802-e7b6-a3a752f67f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST_DATASET/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:01<00:00, 5105132.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_DATASET/MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST_DATASET/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST_DATASET/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 129789.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_DATASET/MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST_DATASET/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST_DATASET/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1271055.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_DATASET/MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST_DATASET/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST_DATASET/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 12219710.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_DATASET/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST_DATASET/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "transforms = Compose([\n",
        "    ToTensor(),\n",
        "])\n",
        "\n",
        "# trainset = MNIST('/content/gdrive/My Drive/MNIST_models/',train=True,transform=transforms,download=True)\n",
        "# testset = MNIST('/content/gdrive/My Drive/MNIST_models/',train=False,transform=transforms,download=True)\n",
        "\n",
        "# download path 정의\n",
        "download_root = './MNIST_DATASET'\n",
        "\n",
        "trainset = MNIST(download_root, transform=transforms, train=True, download=True)\n",
        "testset = MNIST(download_root, transform=transforms, train=False, download=True)\n",
        "\n",
        "\n",
        "args = {\n",
        "    'num_workers' : 1,\n",
        "    'batch_size' : BATCH_SIZE,\n",
        "    'shuffle' : True,\n",
        "}\n",
        "\n",
        "train_loader = DataLoader(trainset,**args)\n",
        "test_loader = DataLoader(testset,**args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./MNIST_DATASET/MNIST"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_8u5nCAM1j4",
        "outputId": "4bece70c-e179-4bba-dbff-769cfac4940d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw9IBUpYZPqb"
      },
      "source": [
        "####Training part(DNN)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTDNN(IMG_SIZE).cuda()\n",
        "\n",
        "# Model의 parameters 수를 확인하기 위한 코드\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(\"number of parameters : {}\".format(num_params))\n",
        "\n",
        "optimizer = Adam(model.parameters(),lr=LEARNING_RATE)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(NUM_EPOCHES):\n",
        "    tot_loss = 0.0\n",
        "\n",
        "    for x,y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\n",
        "        y_ = model(x) # y_ predict\n",
        "        loss = loss_fn(y_, y.cuda()) # loss구할때는 왜 y_predict와 y를 바로 비교하고, compute_acc에서는 torch.max값을 구해서 비교??\n",
        "        loss.backward()\n",
        "        tot_loss+=loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch {}, Loss(train) : {}\".format(epoch+1,tot_loss))\n",
        "    if epoch % 2 == 1:ㅁ\n",
        "        x,y = next(iter(test_loader))\n",
        "        x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\n",
        "        y_ = model(x)\n",
        "        aa, argmax = torch.max(y_,dim=-1) # dim -1 의미는?\n",
        "        print(aa, aa.shape)\n",
        "        print(argmax, argmax.shape)\n",
        "        test_acc = compute_acc(argmax, y.numpy())\n",
        "\n",
        "        print(\"Acc(val) : {}\".format(test_acc))\n",
        "\n",
        "# torch.save(model.state_dict(), \"/content/gdrive/My Drive/MNIST_models/DNN.pt\")"
      ],
      "metadata": {
        "id": "l3ayxTuoU0se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "y값을 확인하기 위한 출력용 코드"
      ],
      "metadata": {
        "id": "n01QSQFoU_6r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nPSsZM0uGs2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a1530e6-3f75-4c75-ca51-bda419c7da74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss(train) : 2.3047361373901367\n",
            "tensor([0.2291, 0.2193, 0.1804, 0.1519, 0.2822, 0.1710, 0.2145, 0.1902, 0.2404,\n",
            "        0.2320, 0.2796, 0.2770, 0.3548, 0.4426, 0.2092, 0.2203, 0.1568, 0.1582,\n",
            "        0.1562, 0.2093, 0.1969, 0.3433, 0.3172, 0.2734, 0.2057, 0.2203, 0.1432,\n",
            "        0.2066, 0.3195, 0.2981, 0.1833, 0.1645, 0.1701, 0.2016, 0.1940, 0.1944,\n",
            "        0.1821, 0.3117, 0.1470, 0.2811, 0.1907, 0.2911, 0.1814, 0.1846, 0.2087,\n",
            "        0.1669, 0.1661, 0.1725, 0.1616, 0.2854, 0.2181, 0.2451, 0.2340, 0.1738,\n",
            "        0.1414, 0.2429, 0.2051, 0.1607, 0.1721, 0.1859, 0.4302, 0.2211, 0.3013,\n",
            "        0.3439, 0.2063, 0.2254, 0.1890, 0.1937, 0.2640, 0.2252, 0.2268, 0.1668,\n",
            "        0.1976, 0.2842, 0.3021, 0.1646, 0.1776, 0.1479, 0.2237, 0.4347, 0.1738,\n",
            "        0.2938, 0.1456, 0.1989, 0.2070, 0.2602, 0.1465, 0.1903, 0.2460, 0.4224,\n",
            "        0.1310, 0.1757, 0.2356, 0.3198, 0.2994, 0.2617, 0.1563, 0.2189, 0.1976,\n",
            "        0.1706, 0.1794, 0.3872, 0.2498, 0.1849, 0.1462, 0.2162, 0.2910, 0.2176,\n",
            "        0.1822, 0.2277, 0.3005, 0.2660, 0.1838, 0.2014, 0.1424, 0.1421, 0.1945,\n",
            "        0.2220, 0.2530, 0.2342, 0.2565, 0.2018, 0.3574, 0.1708, 0.2244, 0.1767,\n",
            "        0.4629, 0.1601, 0.1790, 0.2360, 0.1651, 0.2124, 0.1459, 0.1851, 0.1895,\n",
            "        0.3403, 0.1966, 0.1681, 0.3492, 0.1803, 0.2262, 0.2272, 0.2374, 0.3041,\n",
            "        0.1804, 0.3136, 0.1995, 0.1961, 0.1933, 0.2257, 0.2697, 0.4041, 0.2148,\n",
            "        0.1470, 0.2923, 0.3317, 0.2643, 0.1592, 0.2056, 0.2189, 0.2472, 0.1502,\n",
            "        0.4767, 0.4735, 0.1654, 0.2726, 0.1953, 0.2861, 0.1847, 0.2403, 0.2010,\n",
            "        0.4167, 0.2480, 0.2312, 0.1967, 0.1714, 0.1590, 0.1706, 0.4163, 0.1948,\n",
            "        0.2621, 0.2337, 0.3451, 0.1552, 0.1964, 0.3186, 0.2903, 0.1502, 0.2763,\n",
            "        0.2896, 0.2647, 0.2745, 0.1746, 0.1758, 0.1552, 0.1801, 0.2768, 0.1936,\n",
            "        0.1586, 0.2455, 0.2642, 0.1773, 0.2546, 0.2597, 0.2086, 0.2163, 0.1849,\n",
            "        0.1729, 0.1659, 0.1621, 0.1541, 0.1485, 0.1548, 0.1742, 0.1978, 0.1856,\n",
            "        0.1678, 0.1652, 0.2040, 0.2247, 0.2859, 0.2301, 0.2393, 0.3462, 0.1636,\n",
            "        0.2362, 0.2835, 0.1732, 0.1926, 0.2331, 0.1849, 0.2969, 0.1875, 0.3665,\n",
            "        0.1803, 0.1626, 0.1784, 0.1977, 0.2528, 0.1955, 0.1853, 0.1489, 0.1918,\n",
            "        0.2805, 0.1444, 0.3962, 0.3323, 0.1601, 0.1673, 0.2202, 0.2033, 0.2081,\n",
            "        0.1597, 0.1922, 0.1371, 0.1330], device='cuda:0',\n",
            "       grad_fn=<MaxBackward0>) torch.Size([256])\n",
            "tensor([4, 4, 9, 1, 3, 3, 7, 4, 3, 7, 6, 3, 6, 9, 5, 6, 6, 9, 9, 3, 5, 1, 7, 1,\n",
            "        6, 8, 0, 6, 1, 6, 5, 4, 4, 1, 3, 1, 3, 7, 5, 3, 3, 1, 1, 2, 9, 9, 7, 0,\n",
            "        1, 4, 2, 6, 1, 6, 3, 6, 3, 8, 3, 9, 9, 9, 3, 4, 6, 3, 0, 9, 3, 5, 2, 6,\n",
            "        3, 3, 9, 9, 3, 9, 3, 4, 7, 9, 7, 8, 6, 6, 1, 4, 9, 4, 9, 2, 7, 1, 3, 9,\n",
            "        9, 1, 2, 9, 9, 1, 6, 6, 6, 1, 1, 7, 1, 9, 1, 1, 9, 6, 9, 8, 7, 4, 1, 3,\n",
            "        9, 1, 9, 2, 9, 1, 3, 1, 7, 3, 6, 4, 4, 9, 1, 3, 9, 4, 3, 1, 3, 3, 1, 9,\n",
            "        3, 6, 0, 2, 6, 2, 9, 6, 6, 9, 9, 3, 8, 8, 1, 9, 1, 5, 3, 9, 1, 1, 1, 7,\n",
            "        5, 6, 3, 9, 1, 1, 9, 3, 8, 6, 9, 6, 9, 6, 3, 9, 7, 9, 4, 1, 1, 4, 2, 6,\n",
            "        8, 7, 9, 1, 7, 8, 2, 9, 9, 3, 4, 3, 7, 9, 9, 6, 9, 7, 3, 0, 1, 7, 1, 4,\n",
            "        0, 6, 1, 1, 1, 2, 7, 1, 9, 6, 9, 5, 9, 8, 9, 3, 3, 9, 7, 1, 0, 3, 2, 2,\n",
            "        3, 4, 8, 6, 0, 3, 1, 2, 1, 4, 3, 1, 6, 8, 7, 1], device='cuda:0') torch.Size([256])\n",
            "Acc(val) : 0.2109375\n"
          ]
        }
      ],
      "source": [
        "model = MNISTDNN(IMG_SIZE).cuda()\n",
        "\n",
        "# Model의 parameters 수를 확인하기 위한 코드\n",
        "# model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "# num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "# print(\"number of parameters : {}\".format(num_params))\n",
        "\n",
        "optimizer = Adam(model.parameters(),lr=LEARNING_RATE)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(NUM_EPOCHES):\n",
        "    tot_loss = 0.0\n",
        "\n",
        "    for x,y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\n",
        "        y_ = model(x) # y_ predict\n",
        "        # print(y_, y_.shape)\n",
        "        # print(y, y.shape)\n",
        "        loss = loss_fn(y_, y.cuda()) # loss구할때는 왜 y_predict와 y를 바로 비교하고, compute_acc에서는 torch.max값을 구해서 비교??\n",
        "        loss.backward()\n",
        "        tot_loss+=loss.item()\n",
        "        optimizer.step()\n",
        "        break\n",
        "\n",
        "    print(\"Epoch {}, Loss(train) : {}\".format(epoch+1,tot_loss))\n",
        "    # if epoch % 2 == 1:\n",
        "    if 1 == 1:\n",
        "        x,y = next(iter(test_loader))\n",
        "        x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\n",
        "        y_ = model(x)\n",
        "        aa, argmax = torch.max(y_,dim=-1) # dim -1 의미는 dim의 제일 높은 단계중에서 max값을 찾겠다는 의미, dim을 설정하게 되면, value와 index가 함께 출력되는 특징이 있습니다.\n",
        "        print(aa, aa.shape)\n",
        "        print(argmax, argmax.shape)\n",
        "        test_acc = compute_acc(argmax, y.numpy())\n",
        "\n",
        "        print(\"Acc(val) : {}\".format(test_acc))\n",
        "    break\n",
        "\n",
        "# torch.save(model.state_dict(), \"/content/gdrive/My Drive/MNIST_models/DNN.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CUDA 사용하지 않고 동작하는 코드"
      ],
      "metadata": {
        "id": "JK9ldrJlRsA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = MNISTDNN(IMG_SIZE).cuda()\n",
        "model = MNISTDNN(IMG_SIZE)\n",
        "\n",
        "# Model의 parameters 수를 확인하기 위한 코드\n",
        "# model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "# num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "# print(\"number of parameters : {}\".format(num_params))\n",
        "\n",
        "optimizer = Adam(model.parameters(),lr=LEARNING_RATE)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(NUM_EPOCHES):\n",
        "    tot_loss = 0.0\n",
        "\n",
        "    for x,y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        # x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\n",
        "        x = x.view(-1,IMG_SIZE*IMG_SIZE) # view를 정의하는 이유는 model에서 self.fc1 = nn.Linear(IMG_SIZE*IMG_SIZE,32)의 input 형식에 맞춰주는것임\n",
        "        y_ = model(x)\n",
        "        loss = loss_fn(y_, y)\n",
        "        loss.backward()\n",
        "        tot_loss+=loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch {}, Loss(train) : {}\".format(epoch+1,tot_loss))\n",
        "    if epoch % 2 == 1:\n",
        "        x,y = next(iter(test_loader))\n",
        "        x = x.view(-1,IMG_SIZE*IMG_SIZE)\n",
        "        y_ = model(x)\n",
        "        _, argmax = torch.max(y_,dim=-1)\n",
        "        test_acc = compute_acc(argmax,y.numpy())\n",
        "\n",
        "        print(\"Acc(val) : {}\".format(test_acc))\n",
        "\n",
        "# torch.save(model.state_dict(), \"/content/gdrive/My Drive/MNIST_models/DNN.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K0RNZKpxQYjx",
        "outputId": "06e9eea3-bcc2-4f29-aef9-35e26cc9ba7c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss(train) : 405.0010612010956\n",
            "Epoch 2, Loss(train) : 367.5182956457138\n",
            "Acc(val) : 0.95703125\n",
            "Epoch 3, Loss(train) : 360.7984906435013\n",
            "Epoch 4, Loss(train) : 357.62138509750366\n",
            "Acc(val) : 0.90234375\n",
            "Epoch 5, Loss(train) : 355.5156397819519\n",
            "Epoch 6, Loss(train) : 354.0269241333008\n",
            "Acc(val) : 0.94921875\n",
            "Epoch 7, Loss(train) : 352.9148017168045\n",
            "Epoch 8, Loss(train) : 352.2267256975174\n",
            "Acc(val) : 0.953125\n",
            "Epoch 9, Loss(train) : 351.45687234401703\n",
            "Epoch 10, Loss(train) : 350.8423923254013\n",
            "Acc(val) : 0.9765625\n",
            "Epoch 11, Loss(train) : 350.50638234615326\n",
            "Epoch 12, Loss(train) : 349.9335335493088\n",
            "Acc(val) : 0.9765625\n",
            "Epoch 13, Loss(train) : 349.6529446840286\n",
            "Epoch 14, Loss(train) : 349.2466480731964\n",
            "Acc(val) : 0.9765625\n",
            "Epoch 15, Loss(train) : 348.948228597641\n",
            "Epoch 16, Loss(train) : 348.8442051410675\n",
            "Acc(val) : 0.953125\n",
            "Epoch 17, Loss(train) : 348.59975612163544\n",
            "Epoch 18, Loss(train) : 348.3664346933365\n",
            "Acc(val) : 0.94921875\n",
            "Epoch 19, Loss(train) : 348.17678582668304\n",
            "Epoch 20, Loss(train) : 348.04107320308685\n",
            "Acc(val) : 0.97265625\n",
            "Epoch 21, Loss(train) : 347.82962226867676\n",
            "Epoch 22, Loss(train) : 347.7371804714203\n",
            "Acc(val) : 0.95703125\n",
            "Epoch 23, Loss(train) : 347.5859377384186\n",
            "Epoch 24, Loss(train) : 347.35801923274994\n",
            "Acc(val) : 0.95703125\n",
            "Epoch 25, Loss(train) : 347.3408273458481\n",
            "Epoch 26, Loss(train) : 347.20087790489197\n",
            "Acc(val) : 0.94921875\n",
            "Epoch 27, Loss(train) : 347.0632321834564\n",
            "Epoch 28, Loss(train) : 347.1155848503113\n",
            "Acc(val) : 0.96484375\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-2409a4e957ce>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtot_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"./DNN.pt\")"
      ],
      "metadata": {
        "id": "q3icEKGPO87a"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WyC_PAFPMPLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465255ef-f71a-4a8a-9f43-4bc0dadd03b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc(test) : 0.97265625\n"
          ]
        }
      ],
      "source": [
        "model_test = MNISTDNN(IMG_SIZE).cuda()\n",
        "model_test.load_state_dict(torch.load(\"./DNN.pt\"))\n",
        "model_test.eval()\n",
        "x,y = next(iter(test_loader))\n",
        "x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\n",
        "y_ = model_test(x)\n",
        "_, argmax = torch.max(y_,dim=-1)\n",
        "test_acc = compute_acc(argmax,y.numpy())\n",
        "\n",
        "print(\"Acc(test) : {}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZlMbw_tZLT-"
      },
      "source": [
        "#### Training part(CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Q_hp82IXWJ4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5098ed3-1317-49e3-8996-36b6364483fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters : 2762\n",
            "Epoch 1, Loss(train) : 434.5468850135803\n",
            "Epoch 2, Loss(train) : 361.9365322589874\n",
            "Acc(test) : 0.96484375\n",
            "Epoch 3, Loss(train) : 355.2590903043747\n",
            "Epoch 4, Loss(train) : 352.79480969905853\n",
            "Acc(test) : 0.9609375\n",
            "Epoch 5, Loss(train) : 351.18767166137695\n",
            "Epoch 6, Loss(train) : 350.317409992218\n",
            "Acc(test) : 0.98046875\n",
            "Epoch 7, Loss(train) : 349.603174328804\n",
            "Epoch 8, Loss(train) : 349.0490720272064\n",
            "Acc(test) : 0.98046875\n",
            "Epoch 9, Loss(train) : 348.68840992450714\n",
            "Epoch 10, Loss(train) : 348.3464721441269\n",
            "Acc(test) : 0.984375\n",
            "Epoch 11, Loss(train) : 348.0965973138809\n",
            "Epoch 12, Loss(train) : 347.8390871286392\n",
            "Acc(test) : 0.984375\n",
            "Epoch 13, Loss(train) : 347.7000914812088\n",
            "Epoch 14, Loss(train) : 347.5057452917099\n",
            "Acc(test) : 0.98046875\n",
            "Epoch 15, Loss(train) : 347.3235617876053\n",
            "Epoch 16, Loss(train) : 347.1446521282196\n",
            "Acc(test) : 0.97265625\n",
            "Epoch 17, Loss(train) : 347.08527052402496\n",
            "Epoch 18, Loss(train) : 346.93141782283783\n",
            "Acc(test) : 0.96875\n",
            "Epoch 19, Loss(train) : 346.8935270309448\n",
            "Epoch 20, Loss(train) : 346.7903354167938\n",
            "Acc(test) : 0.96875\n",
            "Epoch 21, Loss(train) : 346.6829446554184\n",
            "Epoch 22, Loss(train) : 346.58509027957916\n",
            "Acc(test) : 0.98046875\n",
            "Epoch 23, Loss(train) : 346.4727681875229\n",
            "Epoch 24, Loss(train) : 346.42340409755707\n",
            "Acc(test) : 0.98828125\n",
            "Epoch 25, Loss(train) : 346.41170370578766\n",
            "Epoch 26, Loss(train) : 346.3118106126785\n",
            "Acc(test) : 0.96875\n",
            "Epoch 27, Loss(train) : 346.30525958538055\n",
            "Epoch 28, Loss(train) : 346.18738651275635\n",
            "Acc(test) : 0.97265625\n",
            "Epoch 29, Loss(train) : 346.09959149360657\n",
            "Epoch 30, Loss(train) : 346.07658195495605\n",
            "Acc(test) : 0.984375\n"
          ]
        }
      ],
      "source": [
        "model = MNISTCNN(IMG_SIZE).cuda()\n",
        "\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "# model.parameters() : list 형태의 파라미터\n",
        "num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "# num_params : 모델 파라미터 수\n",
        "print(\"number of parameters : {}\".format(num_params))\n",
        "\n",
        "optimizer = Adam(model.parameters(),lr=LEARNING_RATE)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(NUM_EPOCHES):\n",
        "    tot_loss = 0.0\n",
        "\n",
        "    for x,y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        x = x.cuda()\n",
        "        y_ = model(x)\n",
        "        loss = loss_fn(y_, y.cuda())\n",
        "        loss.backward()\n",
        "        tot_loss+=loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch {}, Loss(train) : {}\".format(epoch+1,tot_loss))\n",
        "    if epoch % 2 == 1:\n",
        "        model.eval()\n",
        "\n",
        "        x,y = next(iter(test_loader))\n",
        "        x = x.cuda()\n",
        "        y_ = model(x)\n",
        "        _, argmax = torch.max(y_,dim=-1)\n",
        "        test_acc = compute_acc(argmax,y.numpy())\n",
        "\n",
        "        print(\"Acc(test) : {}\".format(test_acc))\n",
        "\n",
        "        model.train()\n",
        "\n",
        "torch.save(model.state_dict(), \"./CNN.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xhN_wmbMR41"
      },
      "outputs": [],
      "source": [
        "model_test = MNISTCNN(IMG_SIZE).cuda()\n",
        "model_test.load_state_dict(torch.load(\"./CNN.pt\"))\n",
        "model_test.eval()\n",
        "x,y = next(iter(test_loader))\n",
        "x = x.cuda()\n",
        "y_ = model_test(x)\n",
        "_, argmax = torch.max(y_,dim=-1)\n",
        "test_acc = compute_acc(argmax,y.numpy())\n",
        "\n",
        "print(\"Acc(test) : {}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSMsL5fKVONu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lab2_2.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}